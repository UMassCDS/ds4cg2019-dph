{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # read in data from MassGov source and merge iteratively #\n",
    "\n",
    "df = pd.read_csv('../data_process/Cancer_UA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "df.columns = ['Geography', 'cancer_admissions_UA']\n",
    "\n",
    "ca2 = pd.read_csv('../data_process/Cancer_AA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "ca2.columns = ['Geography', 'cancer_admissions_AA']\n",
    "\n",
    "df = df.merge(ca2, how='inner', on='Geography')\n",
    "\n",
    "ca3 = pd.read_csv('../data_process/Cancer_UA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "ca3.columns = ['Geography', 'cancer_emergencies_UA']\n",
    "\n",
    "df = df.merge(ca3, how='inner', on='Geography')\n",
    "\n",
    "ca4 = pd.read_csv('../data_process/Cancer_AA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "ca4.columns = ['Geography', 'cancer_emergencies_AA']\n",
    "\n",
    "df = df.merge(ca4, how='inner', on='Geography')\n",
    "\n",
    "cv1 = pd.read_csv('../data_process/CardioVascular_UA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "cv1.columns = ['Geography', 'cardio_admissions_UA']\n",
    "\n",
    "df = df.merge(cv1, how='inner', on='Geography')\n",
    "\n",
    "cv2 = pd.read_csv('../data_process/CardioVascular_AA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "cv2.columns = ['Geography', 'cardio_admissions_AA']\n",
    "\n",
    "df = df.merge(cv2, how='inner', on='Geography')\n",
    "\n",
    "cv3 = pd.read_csv('../data_process/CardioVascular_UA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "cv3.columns = ['Geography', 'cardio_emergencies_UA']\n",
    "\n",
    "df = df.merge(cv3, how='inner', on='Geography')\n",
    "\n",
    "cv4 = pd.read_csv('../data_process/CardioVascular_AA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "cv4.columns = ['Geography', 'cardio_emergencies_AA']\n",
    "\n",
    "df = df.merge(cv4, how='inner', on='Geography')\n",
    "\n",
    "d1 = pd.read_csv('../data_process/Diabetes_UA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "d1.columns = ['Geography', 'Diabetes_admissions_UA']\n",
    "\n",
    "df = df.merge(d1, how='inner', on='Geography')\n",
    "\n",
    "d2 = pd.read_csv('../data_process/Diabetes_AA_AD.csv', usecols=['Geography','Measure'])\n",
    "d2.columns = ['Geography', 'Diabetes_admissions_AA']\n",
    "\n",
    "df = df.merge(d2, how='inner', on='Geography')\n",
    "\n",
    "d3 = pd.read_csv('../data_process/Diabetes_UA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "d3.columns = ['Geography', 'Diabetes_emergencies_UA']\n",
    "\n",
    "df = df.merge(d3, how='inner', on='Geography')\n",
    "\n",
    "d4 = pd.read_csv('../data_process/Diabetes_AA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "d4.columns = ['Geography', 'Diabetes_emergencies_AA']\n",
    "\n",
    "df = df.merge(d4, how='inner', on='Geography')\n",
    "\n",
    "m1 = pd.read_csv('../data_process/MentalHealth_UA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "m1.columns = ['Geography', 'Mental_admissions_UA']\n",
    "\n",
    "df = df.merge(m1, how='inner', on='Geography')\n",
    "\n",
    "m2 = pd.read_csv('../data_process/MentalHealth_AA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "m2.columns = ['Geography', 'Mental_admissions_AA']\n",
    "\n",
    "df = df.merge(m2, how='inner', on='Geography')\n",
    "\n",
    "m3 = pd.read_csv('../data_process/MentalHealth_UA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "m3.columns = ['Geography', 'Mental_emergencies_UA']\n",
    "\n",
    "df = df.merge(m3, how='inner', on='Geography')\n",
    "\n",
    "m4 = pd.read_csv('../data_process/MentalHealth_AA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "m4.columns = ['Geography', 'Mental_emergencies_AA']\n",
    "\n",
    "df = df.merge(m4, how='inner', on='Geography')\n",
    "\n",
    "s1 = pd.read_csv('../data_process/Stroke_UA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "s1.columns = ['Geography', 'Stroke_admissions_UA']\n",
    "\n",
    "df = df.merge(s1, how='inner', on='Geography')\n",
    "\n",
    "s2 = pd.read_csv('../data_process/Stroke_AA_AD.csv', usecols=['Geography', 'Measure'])\n",
    "s2.columns = ['Geography', 'Stroke_admissions_AA']\n",
    "\n",
    "df = df.merge(s2, how='inner', on='Geography')\n",
    "\n",
    "s3 = pd.read_csv('../data_process/Stroke_UA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "s3.columns = ['Geography', 'Stroke_emergencies_UA']\n",
    "\n",
    "df = df.merge(s3, how='inner', on='Geography')\n",
    "\n",
    "s4 = pd.read_csv('../data_process/Stroke_AA_ED.csv', usecols=['Geography', 'Measure'])\n",
    "s4.columns = ['Geography', 'Stroke_emergencies_AA']\n",
    "\n",
    "df_main = df.merge(s4, how='inner', on='Geography')\n",
    "df_main.set_index('Geography', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cancer_admissions_UA</th>\n",
       "      <th>cancer_admissions_AA</th>\n",
       "      <th>cancer_emergencies_UA</th>\n",
       "      <th>cancer_emergencies_AA</th>\n",
       "      <th>cardio_admissions_UA</th>\n",
       "      <th>cardio_admissions_AA</th>\n",
       "      <th>cardio_emergencies_UA</th>\n",
       "      <th>cardio_emergencies_AA</th>\n",
       "      <th>Diabetes_admissions_UA</th>\n",
       "      <th>Diabetes_admissions_AA</th>\n",
       "      <th>...</th>\n",
       "      <th>Stroke_emergencies_AA</th>\n",
       "      <th>% Exemplary</th>\n",
       "      <th>% Proficient</th>\n",
       "      <th>% Needs Improvement</th>\n",
       "      <th>% Unsatisfactory</th>\n",
       "      <th>Reading / Writing</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>% Dropout All Grades</th>\n",
       "      <th>Attending Coll./Univ. (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abington</th>\n",
       "      <td>423.9</td>\n",
       "      <td>356.4</td>\n",
       "      <td>NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>1713.3</td>\n",
       "      <td>1645.6</td>\n",
       "      <td>494.6</td>\n",
       "      <td>463.4</td>\n",
       "      <td>206.1</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>113.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>550.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acton</th>\n",
       "      <td>347.4</td>\n",
       "      <td>314.2</td>\n",
       "      <td>NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>933.7</td>\n",
       "      <td>893.6</td>\n",
       "      <td>443</td>\n",
       "      <td>413.8</td>\n",
       "      <td>56.5</td>\n",
       "      <td>66.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>656.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>684.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acushnet</th>\n",
       "      <td>460.9</td>\n",
       "      <td>337</td>\n",
       "      <td>NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>2016.5</td>\n",
       "      <td>1427.9</td>\n",
       "      <td>422.5</td>\n",
       "      <td>347.4</td>\n",
       "      <td>182.4</td>\n",
       "      <td>170.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>7.4</td>\n",
       "      <td>84.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adams</th>\n",
       "      <td>429.1</td>\n",
       "      <td>324.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1704.4</td>\n",
       "      <td>1149.8</td>\n",
       "      <td>679.4</td>\n",
       "      <td>588.9</td>\n",
       "      <td>NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>13.3</td>\n",
       "      <td>84.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>522.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agawam</th>\n",
       "      <td>472.9</td>\n",
       "      <td>343.6</td>\n",
       "      <td>NS</td>\n",
       "      <td>NS</td>\n",
       "      <td>2347</td>\n",
       "      <td>1487.7</td>\n",
       "      <td>685</td>\n",
       "      <td>504.7</td>\n",
       "      <td>250.4</td>\n",
       "      <td>199.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NS</td>\n",
       "      <td>11.7</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>555.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>77.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cancer_admissions_UA cancer_admissions_AA cancer_emergencies_UA  \\\n",
       "Geography                                                                   \n",
       "Abington                 423.9                356.4                    NS   \n",
       "Acton                    347.4                314.2                    NS   \n",
       "Acushnet                 460.9                  337                    NS   \n",
       "Adams                    429.1                324.1                     0   \n",
       "Agawam                   472.9                343.6                    NS   \n",
       "\n",
       "          cancer_emergencies_AA cardio_admissions_UA cardio_admissions_AA  \\\n",
       "Geography                                                                   \n",
       "Abington                     NS               1713.3               1645.6   \n",
       "Acton                        NS                933.7                893.6   \n",
       "Acushnet                     NS               2016.5               1427.9   \n",
       "Adams                         0               1704.4               1149.8   \n",
       "Agawam                       NS                 2347               1487.7   \n",
       "\n",
       "          cardio_emergencies_UA cardio_emergencies_AA Diabetes_admissions_UA  \\\n",
       "Geography                                                                      \n",
       "Abington                  494.6                 463.4                  206.1   \n",
       "Acton                       443                 413.8                   56.5   \n",
       "Acushnet                  422.5                 347.4                  182.4   \n",
       "Adams                     679.4                 588.9                     NS   \n",
       "Agawam                      685                 504.7                  250.4   \n",
       "\n",
       "          Diabetes_admissions_AA            ...             \\\n",
       "Geography                                   ...              \n",
       "Abington                     192            ...              \n",
       "Acton                       66.6            ...              \n",
       "Acushnet                   170.9            ...              \n",
       "Adams                         NS            ...              \n",
       "Agawam                     199.6            ...              \n",
       "\n",
       "          Stroke_emergencies_AA % Exemplary % Proficient % Needs Improvement  \\\n",
       "Geography                                                                      \n",
       "Abington                  113.7        12.7         86.0                 0.7   \n",
       "Acton                        NS        13.1         86.5                 0.4   \n",
       "Acushnet                     NS         7.4         84.0                 8.6   \n",
       "Adams                        NS        13.3         84.8                 1.9   \n",
       "Agawam                       NS        11.7         88.0                 0.3   \n",
       "\n",
       "          % Unsatisfactory Reading / Writing Writing   Math  \\\n",
       "Geography                                                     \n",
       "Abington               0.7             550.0     NaN  535.0   \n",
       "Acton                  0.0             656.0     NaN  684.0   \n",
       "Acushnet               0.0               NaN     NaN    NaN   \n",
       "Adams                  0.0             522.0     NaN  522.0   \n",
       "Agawam                 0.0             548.0     NaN  555.0   \n",
       "\n",
       "          % Dropout All Grades Attending Coll./Univ. (%)  \n",
       "Geography                                                 \n",
       "Abington                   1.2                      69.9  \n",
       "Acton                      0.2                      90.0  \n",
       "Acushnet                   NaN                       NaN  \n",
       "Adams                      3.0                      66.3  \n",
       "Agawam                     1.1                      77.8  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# helper function to fix location entries and filter out unneccessary rows from DOE data \n",
    "all_communities = df_main.index.tolist()\n",
    "def fix_location(df, place_col, val_cols):\n",
    "    for place in df[place_col]:\n",
    "        if place not in all_communities:\n",
    "            if '-' in place:\n",
    "                first = place.split('-')[0]\n",
    "                second = place.split('-')[1]\n",
    "                if place=='Bristol-Plymouth Regional Vocational Technical':\n",
    "                    second = 'Plymouth'\n",
    "                if first in all_communities:\n",
    "                    new = {place_col : first}\n",
    "                    for val_col in val_cols:\n",
    "                        new[val_col] = df.loc[df.index[df[place_col]==place]][val_col].values[0]\n",
    "                    df = df.append(new, ignore_index=True)\n",
    "                if second in all_communities:\n",
    "                    new = {place_col : second}\n",
    "                    for val_col in val_cols:\n",
    "                        new[val_col] = df.loc[df.index[df[place_col]==place]][val_col].values[0]\n",
    "                    df = df.append(new, ignore_index=True)\n",
    "            df.drop(df.index[df[place_col]==place], inplace=True) \n",
    "    df.set_index(place_col, inplace=True)\n",
    "    df = df.loc[~df.index.duplicated(keep='first')]\n",
    "    return df\n",
    "\n",
    "            # read in data from DOE source, fix columns and merge iteratively #\n",
    "e1 = pd.read_excel('../data_process/EducatorEvalPerf.xlsx', skiprows=1, \\\n",
    "                  usecols=[0, 5, 6, 7, 8])\n",
    "val_cols = list(e1.columns)\n",
    "val_cols.remove('District Name')\n",
    "e1 = fix_location(e1, 'District Name', val_cols)\n",
    "df_main = df_main.join(e1, how='left')\n",
    "\n",
    "e2 = pd.read_excel('../data_process/sat_performance.xlsx', skiprows=1,\\\n",
    "                  usecols=[0, 3, 4, 5])\n",
    "val_cols = list(e2.columns)\n",
    "val_cols.remove('District Name')\n",
    "e2 = fix_location(e2, 'District Name', val_cols)\n",
    "df_main = df_main.join(e2, how='left')\n",
    "\n",
    "e3 = pd.read_excel('../data_process/dropout.xlsx', skiprows=1, usecols=[0, 4])\n",
    "val_cols = list(e3.columns)\n",
    "val_cols.remove('District Name')\n",
    "e3 = fix_location(e3, 'District Name', val_cols)\n",
    "df_main = df_main.join(e3, how='left')\n",
    "\n",
    "e4 = pd.read_excel('../data_process/Gradsattendingcollege.xlsx', skiprows=1,\\\n",
    "                  usecols=[0, 4])\n",
    "val_cols = list(e4.columns)\n",
    "val_cols.remove('District Name')\n",
    "e4 = fix_location(e4, 'District Name', val_cols)\n",
    "df_main = df_main.join(e4, how='left')\n",
    "display(df_main.head())\n",
    "                                    # sanity check #\n",
    "print(set(e1.index).issubset(set(all_communities)))\n",
    "print(set(e2.index).issubset(set(all_communities)))\n",
    "print(set(e3.index).issubset(set(all_communities)))\n",
    "print(set(e4.index).issubset(set(all_communities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Abington', 'Acton', 'Acushnet', 'Adams', 'Agawam', 'Alford',\n",
       "       'Amesbury', 'Amherst', 'Andover', 'Aquinnah',\n",
       "       ...\n",
       "       'Wilmington', 'Winchendon', 'Winchester', 'Windsor', 'Winthrop',\n",
       "       'Woburn', 'Worcester', 'Worthington', 'Wrentham', 'Yarmouth'],\n",
       "      dtype='object', name='Geography', length=351)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = pd.read_csv('../data_process/tobaccoDensity.csv', \\\n",
    "                                            usecols=['Geography', 'Measurement'])\n",
    "t.set_index('Geography', inplace=True)\n",
    "t = t.rename(columns={'Measurement':'tobaccoDensity'})\n",
    "df_main = df_main.join(t, how='inner')\n",
    "\n",
    "M = pd.read_excel('../data_process/Mun_Credit_Ratings.xls', usecols=[1, 12],\n",
    "                                                         names = ['Name', 'MunCreditRating'])\n",
    "M = fix_location(M, 'Name', ['MunCreditRating'])\n",
    "df_main = df_main.join(M, how='left')\n",
    "\n",
    "## FINAL DATAFRAME ##\n",
    "display(df_main.index)\n",
    "df_main.to_csv('../data_process/subset1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
